## 참석자
김신곤, 김재영, 박세진, 손희락, 심우창, 이상준, 전상민

## 프로젝트 진행 상황
- 상준님 : tf-idf의 tokenizer를 어떤 걸 사용해야할지 모르겠다! 고정을 시키는 게 맞을까? 모델 네임을 어떻게 전달해야할까
  - data_args와 model_name_or_path는 inference 과정에서 바뀐다
  - model이랑 tokenizer name을 다르게 설정해주면? ... 다르게 적어도 덮어씌워지기 때문에 다르게 적용되지 않을 것 같음.
  - 희락님의 pr에서 inference 같이 실행하는 부분...(train.py에서) 인자를 추가했을 때 inference 시에도 그 인자 여부를 좀 적어줬으면 좋겠음
    - retrieval type같은... 그런 것들...
    - 근데 현재 희락님이 이 부분들 수정 중. retrival_type으로 바꾸고 data_args를 model_args로 바꾸고... (sparse, dense, elastic) 세 가지가 있어서 작업 중.
- 재영님 : 학습 안 되는 건 해결했음. 희락님이 dense 구현하신 거 가져와서 잘 하니깐... 되더라...~
  - dpr과 bm25를 비교했을 때 dpr이 더 못 뽑더라,,,~ 되게 뜬금없는 passage를 가져오는 것 같아. 도움이 안 되는 것 같기도 하고... ㅠ.ㅠ
  - k=10, 30으로 re-ranking을 하고 봤는데... 상준님이 올려주신 결과랑 비교했을 때 0.1점정도 높은 수준
  - 학습할 때는 batch size 32로 잡음. 그래서 64개중에 정답 하나 고름. 64개 중에 한 개는 잘 고르는 것 같은데 실제로 retrieval에서 실험을 할 때는 2천 개에서 한 개를 고르기 때문에 거기서는 잘 못 고르는 것 같음
    - batch size 16일 때 너무 별로인 것 같아서 32로 올렸음. 근데 올렸음에도 불구하고 큰 차이는 없었던 것 같음
    - **비교를 위해서는 기준이 정확해야할 것 같아요**
  - bm25는 상준님이랑 똑같음... 근데 dense가 도움이 안 되는 것 같아. normalize를 하고 bm25에 가중치를 1.2배정도 더 주고 나니 dpr이 다 빠져버림.
    - dense에 더 가중치를 주고 실험을 돌리는 것이 좋을듯.
    - dense가 잘 안 됐던 게 학습량의 문제가 아닐까? 생각은 들지만 그래도 혹~시 모르니 가중치 실험도 해보삼
    - k의 크기가 작은 것도 하나의 요인이 되지 않았을까 싶음. 
    - 1등 조는 1:1로 가중치를 뒀을 때 나쁘지 않았다고 써있더라.
- 희락님 : elastic 시도했음. 근데 훨씬 빠르더라!!!!!!!!!!


## 논문 review

